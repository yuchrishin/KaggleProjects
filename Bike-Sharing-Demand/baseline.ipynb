{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle - Bike Sharing Demands - Baseline\n",
    "**Author: Chris Shin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library imports\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "# Third-Party Library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "submission = pd.read_csv('./data/sampleSubmission.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's generally better to do feature engineering separately on the training and test sets to avoid data leakage. Data leakage occurs when information from the test set is used to create features or make decisions about the model. This can lead to overfitting and poor performance on new, unseen data.\n",
    "\n",
    "When you engineer features on the entire dataset, you risk incorporating information from the test set into your model, which can lead to over-optimistic evaluation metrics during training. Then when you evaluate your model on the test set, it may perform poorly because it was never exposed to the test set during training.\n",
    "\n",
    "Therefore, it's recommended to perform feature engineering on the training set first, and then transform the test set using the same transformations applied to the training set. This ensures that your model hasn't been exposed to information from the test set during training and provides a more accurate evaluation of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(data):\n",
    "    df = data.copy()\n",
    "    df['weather'] = df['weather'].replace(4, 3)\n",
    "    df['year'] = df['datetime'].apply(lambda x: x.split()[0].split('-')[0]).astype(int)\n",
    "    df['month'] = df['datetime'].apply(lambda x: x.split()[0].split('-')[1]).astype(int)\n",
    "    df['day'] = df['datetime'].apply(lambda x: x.split()[0].split('-')[2]).astype(int)\n",
    "    df['hour'] = df['datetime'].apply(lambda x: x.split()[1].split(':')[0]).astype(int)\n",
    "    df['weekday'] = df['datetime'].apply(lambda x: x.split()[0]).apply(lambda dateString: calendar.day_name[datetime.strptime(dateString, '%Y-%m-%d').weekday()])\n",
    "    df['season'] = df['season'].map({1: 'Spring',\n",
    "                                        2: 'Summer',\n",
    "                                        3: 'Fall',\n",
    "                                        4: 'Winter'})\n",
    "    # df = pd.get_dummies(df, columns=['season', 'weekday'])\n",
    "\n",
    "    # create an instance of the encoder with categorical feature indices\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    categorical_cols = ['season', 'weekday']\n",
    "\n",
    "    # fit and transform the encoded values to the DataFrame\n",
    "    encoded_values = encoder.fit_transform(df[categorical_cols])\n",
    "    feature_names = encoder.get_feature_names_out(input_features=['season', 'weekday'])\n",
    "    df_encoded = pd.DataFrame(encoded_values, columns=feature_names)\n",
    "\n",
    "    # drop original categorical columns and join the encoded DataFrame to the original\n",
    "    df = df.drop(categorical_cols, axis=1)\n",
    "    df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "    drop_features = ['casual', 'registered', 'datetime', 'windspeed']\n",
    "    df = df.drop([col for col in df.columns if col in drop_features], axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead` Error was shwoing even though using .loc to set the value. But the error disappear after using .copy() function. Why?\n",
    "\n",
    "The reason why the warning disappeared is that by using .copy(), you created a new copy of the original DataFrame, rather than a view of the original data. This means that any modifications made to the new copy will not affect the original data.\n",
    "\n",
    "When you make a slice of a DataFrame, like df['datetime'] in your example, it creates a view of the original DataFrame rather than a new copy. If you modify the view, it may modify the original data as well, depending on the context. This can lead to unexpected behavior, so Pandas gives a warning to alert you to the potential issue.\n",
    "\n",
    "By creating a new copy with .copy(), you avoid modifying the original data and therefore avoid the warning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `One-Hot-Encoding vs get_dummies`\n",
    "\n",
    "Both one hot encoding and get_dummies are techniques used to convert categorical variables into numerical representations that can be used in machine learning models.\n",
    "\n",
    "The main difference between them is that one hot encoding is a general term for encoding categorical variables with multiple levels, while get_dummies is a specific function in the Pandas library that creates dummy variables for each level of a categorical variable.\n",
    "\n",
    "In one hot encoding, a binary vector is created for each category of a categorical variable. The vector has a length equal to the number of unique categories in the variable, and each element is either 0 or 1, representing whether or not the corresponding category is present in the observation.\n",
    "\n",
    "On the other hand, get_dummies function creates a binary column for each category in the input variable. The resulting dataframe has a binary column for each category, where a 1 represents the presence of the category in that observation, and 0 represents the absence.\n",
    "\n",
    "Both techniques have their advantages and disadvantages, and the choice between them depends on the specific problem at hand. One hot encoding is more memory-efficient and suitable for large datasets with many unique categories, but it can create a large number of features that may lead to overfitting. On the other hand, get_dummies creates a more interpretable output and may be more suitable for smaller datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuchie\\Desktop\\DataScience\\kaggle_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yuchie\\Desktop\\DataScience\\kaggle_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train = feature_engineer(train)\n",
    "X_test = feature_engineer(test)\n",
    "\n",
    "X_train = X_train.drop('count', axis=1)\n",
    "y_train = train['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "      <th>weekday_Friday</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [holiday, workingday, weather, temp, atemp, humidity, year, month, day, hour, season_Fall, season_Spring, season_Summer, season_Winter, weekday_Friday, weekday_Monday, weekday_Saturday, weekday_Sunday, weekday_Thursday, weekday_Tuesday, weekday_Wednesday]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[X_train.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred, convertExp=True):\n",
    "\n",
    "    if convertExp:\n",
    "        y_true = np.exp(y_true)\n",
    "        y_pred = np.exp(y_pred)\n",
    "\n",
    "    log_true = np.nan_to_num(np.log(y_true + 1))\n",
    "    log_pred = np.nan_to_num(np.log(y_pred + 1))\n",
    "\n",
    "    rmsle_result = np.sqrt(np.mean((log_true - log_pred) ** 2))\n",
    "    return rmsle_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression()\n",
    "\n",
    "log_y_train = np.log(y_train)\n",
    "linear_reg.fit(X_train, log_y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = linear_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear REgression RMSLE: 1.0122\n"
     ]
    }
   ],
   "source": [
    "print(f\"Linear REgression RMSLE: {rmsle(log_y_train, preds, True):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearreg_preds = linear_reg.predict(X_test)\n",
    "submission['count'] = np.exp(linearreg_preds)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, we create a `Pipeline` object called `feat_eng_pipe` that will encapsulate the entire feature engineering process.\n",
    "\n",
    "2. The pipeline consists of two steps, each defined as a tuple with two elements: the name of the step and the corresponding estimator/transformer object.\n",
    "\n",
    "3. The first step is named `feat_eng` and it uses the `FunctionTransformer` object to apply the `feature_engineer` function to the input data. This function takes a dataframe and performs various transformations on its columns, such as splitting the datetime column into year, month, day, and hour columns, replacing the 'weather' column value of 4 with 3, mapping the 'season' column to categorical values, and dropping some columns that are not relevant for our analysis.\n",
    "\n",
    "4. The second step is named `encoder` and it uses the `ColumnTransformer` object to apply one-hot encoding to the categorical columns 'season' and 'weekday'. One-hot encoding is a technique used to transform categorical data into a numerical format that can be used in machine learning models. The `ColumnTransformer` object takes a list of transformers, each defined as a tuple with three elements: the name of the transformer, the estimator/transformer object, and the list of column names to be transformed. In this case, we only have one transformer, which is a `OneHotEncoder` object that ignores unknown categories and returns a dense matrix. The `remainder` parameter is set to 'passthrough', which means that any remaining columns not specified in the list of transformers should be passed through without any changes.\n",
    "\n",
    "5. The `feat_eng_pipe` pipeline is now ready to be used for feature engineering on a dataset. We can pass the input data to the pipeline using the `fit_transform` method, which applies the transformations defined in the pipeline sequentially. The output of the pipeline will be a numpy array with the transformed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuchie\\Desktop\\DataScience\\kaggle_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;feat_eng_pipe&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;feat_eng&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function feature_engineer at 0x000002680D4BB6A0&gt;)),\n",
       "                                 (&#x27;encoder&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;one_hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False),\n",
       "                                                                   [&#x27;season&#x27;,\n",
       "                                                                    &#x27;weekday&#x27;])]))])),\n",
       "                (&#x27;model_pipe&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;linear_reg&#x27;, LinearRegression())]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;feat_eng_pipe&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;feat_eng&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function feature_engineer at 0x000002680D4BB6A0&gt;)),\n",
       "                                 (&#x27;encoder&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;one_hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False),\n",
       "                                                                   [&#x27;season&#x27;,\n",
       "                                                                    &#x27;weekday&#x27;])]))])),\n",
       "                (&#x27;model_pipe&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;linear_reg&#x27;, LinearRegression())]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feat_eng_pipe: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;feat_eng&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function feature_engineer at 0x000002680D4BB6A0&gt;)),\n",
       "                (&#x27;encoder&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;one_hot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;season&#x27;, &#x27;weekday&#x27;])]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function feature_engineer at 0x000002680D4BB6A0&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">encoder: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;one_hot&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse=False),\n",
       "                                 [&#x27;season&#x27;, &#x27;weekday&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one_hot</label><div class=\"sk-toggleable__content\"><pre>[&#x27;season&#x27;, &#x27;weekday&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;holiday&#x27;, &#x27;workingday&#x27;, &#x27;weather&#x27;, &#x27;temp&#x27;, &#x27;atemp&#x27;, &#x27;humidity&#x27;, &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;, &#x27;hour&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model_pipe: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;linear_reg&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('feat_eng_pipe',\n",
       "                 Pipeline(steps=[('feat_eng',\n",
       "                                  FunctionTransformer(func=<function feature_engineer at 0x000002680D4BB6A0>)),\n",
       "                                 ('encoder',\n",
       "                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                    transformers=[('one_hot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False),\n",
       "                                                                   ['season',\n",
       "                                                                    'weekday'])]))])),\n",
       "                ('model_pipe',\n",
       "                 Pipeline(steps=[('linear_reg', LinearRegression())]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to perform some feature engineering on the input data\n",
    "def feature_engineer(data):\n",
    "    # Make a copy of the input data to avoid modifying the original data\n",
    "    df = data.copy()\n",
    "    # Replace any instances of 4 in the 'weather' column with 3\n",
    "    df['weather'] = df['weather'].replace(4, 3)\n",
    "    # Extract the year, month, day, and hour from the 'datetime' column and create new columns for each\n",
    "    df['year'] = df['datetime'].apply(lambda x: x.split()[0].split('-')[0]).astype(int)\n",
    "    df['month'] = df['datetime'].apply(lambda x: x.split()[0].split('-')[1]).astype(int)\n",
    "    df['day'] = df['datetime'].apply(lambda x: x.split()[0].split('-')[2]).astype(int)\n",
    "    df['hour'] = df['datetime'].apply(lambda x: x.split()[1].split(':')[0]).astype(int)\n",
    "    # Extract the weekday from the 'datetime' column and map the values to the corresponding day name\n",
    "    df['weekday'] = df['datetime'].apply(lambda x: x.split()[0]).apply(lambda dateString: calendar.day_name[datetime.strptime(dateString, '%Y-%m-%d').weekday()])\n",
    "    # Map the values in the 'season' column from integers to corresponding season names\n",
    "    df['season'] = df['season'].map({1: 'Spring',\n",
    "                                        2: 'Summer',\n",
    "                                        3: 'Fall',\n",
    "                                        4: 'Winter'})\n",
    "    # Drop unnecessary columns from the DataFrame\n",
    "    drop_features = ['casual', 'registered', 'datetime', 'windspeed']\n",
    "    df = df.drop([col for col in df.columns if col in drop_features], axis=1)\n",
    "    # Return the modified DataFrame\n",
    "    return df\n",
    "\n",
    "# Define the categorical columns to be one-hot encoded\n",
    "categorical_cols = ['season', 'weekday']\n",
    "\n",
    "# Create a pipeline for feature engineering using FunctionTransformer and ColumnTransformer\n",
    "feat_eng_pipe = Pipeline([\n",
    "    ('feat_eng', FunctionTransformer(feature_engineer)), # use feature_engineer function to engineer data\n",
    "    ('encoder', ColumnTransformer([\n",
    "        ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse=False), categorical_cols) # one-hot encode categorical columns\n",
    "    ], remainder='passthrough')) # passthrough any other columns not specified in the ColumnTransformer\n",
    "])\n",
    "\n",
    "# Create a pipeline for modeling using LinearRegression\n",
    "model_pipe = Pipeline([\n",
    "    ('linear_reg', LinearRegression()) # linear regression model\n",
    "])\n",
    "\n",
    "# Combine the feature engineering and modeling pipelines into a single pipeline using Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('feat_eng_pipe', feat_eng_pipe), # feature engineering pipeline\n",
    "    ('model_pipe', model_pipe) # modeling pipeline\n",
    "])\n",
    "\n",
    "# Split the input data into the predictor variables (X_train) and target variable (y_train)\n",
    "X_train = train.drop(['count'], axis=1)\n",
    "y_train = train['count']\n",
    "# Transform the target variable by taking the natural logarithm\n",
    "log_y_train = np.log(y_train)\n",
    "\n",
    "# Fit the entire pipeline to the training data and make predictions on the test data\n",
    "pipeline.fit(X_train, log_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = feat_eng_pipe.transform(X_train)\n",
    "transformed_col_names = feat_eng_pipe.named_steps['encoder'].get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_hot__season_Fall</th>\n",
       "      <th>one_hot__season_Spring</th>\n",
       "      <th>one_hot__season_Summer</th>\n",
       "      <th>one_hot__season_Winter</th>\n",
       "      <th>one_hot__weekday_Friday</th>\n",
       "      <th>one_hot__weekday_Monday</th>\n",
       "      <th>one_hot__weekday_Saturday</th>\n",
       "      <th>one_hot__weekday_Sunday</th>\n",
       "      <th>one_hot__weekday_Thursday</th>\n",
       "      <th>one_hot__weekday_Tuesday</th>\n",
       "      <th>...</th>\n",
       "      <th>remainder__holiday</th>\n",
       "      <th>remainder__workingday</th>\n",
       "      <th>remainder__weather</th>\n",
       "      <th>remainder__temp</th>\n",
       "      <th>remainder__atemp</th>\n",
       "      <th>remainder__humidity</th>\n",
       "      <th>remainder__year</th>\n",
       "      <th>remainder__month</th>\n",
       "      <th>remainder__day</th>\n",
       "      <th>remainder__hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.58</td>\n",
       "      <td>19.695</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.76</td>\n",
       "      <td>17.425</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.94</td>\n",
       "      <td>15.910</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.94</td>\n",
       "      <td>17.425</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>16.665</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10886 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       one_hot__season_Fall  one_hot__season_Spring  one_hot__season_Summer  \\\n",
       "0                       0.0                     1.0                     0.0   \n",
       "1                       0.0                     1.0                     0.0   \n",
       "2                       0.0                     1.0                     0.0   \n",
       "3                       0.0                     1.0                     0.0   \n",
       "4                       0.0                     1.0                     0.0   \n",
       "...                     ...                     ...                     ...   \n",
       "10881                   0.0                     0.0                     0.0   \n",
       "10882                   0.0                     0.0                     0.0   \n",
       "10883                   0.0                     0.0                     0.0   \n",
       "10884                   0.0                     0.0                     0.0   \n",
       "10885                   0.0                     0.0                     0.0   \n",
       "\n",
       "       one_hot__season_Winter  one_hot__weekday_Friday  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "10881                     1.0                      0.0   \n",
       "10882                     1.0                      0.0   \n",
       "10883                     1.0                      0.0   \n",
       "10884                     1.0                      0.0   \n",
       "10885                     1.0                      0.0   \n",
       "\n",
       "       one_hot__weekday_Monday  one_hot__weekday_Saturday  \\\n",
       "0                          0.0                        1.0   \n",
       "1                          0.0                        1.0   \n",
       "2                          0.0                        1.0   \n",
       "3                          0.0                        1.0   \n",
       "4                          0.0                        1.0   \n",
       "...                        ...                        ...   \n",
       "10881                      0.0                        0.0   \n",
       "10882                      0.0                        0.0   \n",
       "10883                      0.0                        0.0   \n",
       "10884                      0.0                        0.0   \n",
       "10885                      0.0                        0.0   \n",
       "\n",
       "       one_hot__weekday_Sunday  one_hot__weekday_Thursday  \\\n",
       "0                          0.0                        0.0   \n",
       "1                          0.0                        0.0   \n",
       "2                          0.0                        0.0   \n",
       "3                          0.0                        0.0   \n",
       "4                          0.0                        0.0   \n",
       "...                        ...                        ...   \n",
       "10881                      0.0                        0.0   \n",
       "10882                      0.0                        0.0   \n",
       "10883                      0.0                        0.0   \n",
       "10884                      0.0                        0.0   \n",
       "10885                      0.0                        0.0   \n",
       "\n",
       "       one_hot__weekday_Tuesday  ...  remainder__holiday  \\\n",
       "0                           0.0  ...                 0.0   \n",
       "1                           0.0  ...                 0.0   \n",
       "2                           0.0  ...                 0.0   \n",
       "3                           0.0  ...                 0.0   \n",
       "4                           0.0  ...                 0.0   \n",
       "...                         ...  ...                 ...   \n",
       "10881                       0.0  ...                 0.0   \n",
       "10882                       0.0  ...                 0.0   \n",
       "10883                       0.0  ...                 0.0   \n",
       "10884                       0.0  ...                 0.0   \n",
       "10885                       0.0  ...                 0.0   \n",
       "\n",
       "       remainder__workingday  remainder__weather  remainder__temp  \\\n",
       "0                        0.0                 1.0             9.84   \n",
       "1                        0.0                 1.0             9.02   \n",
       "2                        0.0                 1.0             9.02   \n",
       "3                        0.0                 1.0             9.84   \n",
       "4                        0.0                 1.0             9.84   \n",
       "...                      ...                 ...              ...   \n",
       "10881                    1.0                 1.0            15.58   \n",
       "10882                    1.0                 1.0            14.76   \n",
       "10883                    1.0                 1.0            13.94   \n",
       "10884                    1.0                 1.0            13.94   \n",
       "10885                    1.0                 1.0            13.12   \n",
       "\n",
       "       remainder__atemp  remainder__humidity  remainder__year  \\\n",
       "0                14.395                 81.0           2011.0   \n",
       "1                13.635                 80.0           2011.0   \n",
       "2                13.635                 80.0           2011.0   \n",
       "3                14.395                 75.0           2011.0   \n",
       "4                14.395                 75.0           2011.0   \n",
       "...                 ...                  ...              ...   \n",
       "10881            19.695                 50.0           2012.0   \n",
       "10882            17.425                 57.0           2012.0   \n",
       "10883            15.910                 61.0           2012.0   \n",
       "10884            17.425                 61.0           2012.0   \n",
       "10885            16.665                 66.0           2012.0   \n",
       "\n",
       "       remainder__month  remainder__day  remainder__hour  \n",
       "0                   1.0             1.0              0.0  \n",
       "1                   1.0             1.0              1.0  \n",
       "2                   1.0             1.0              2.0  \n",
       "3                   1.0             1.0              3.0  \n",
       "4                   1.0             1.0              4.0  \n",
       "...                 ...             ...              ...  \n",
       "10881              12.0            19.0             19.0  \n",
       "10882              12.0            19.0             20.0  \n",
       "10883              12.0            19.0             21.0  \n",
       "10884              12.0            19.0             22.0  \n",
       "10885              12.0            19.0             23.0  \n",
       "\n",
       "[10886 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed_df = pd.DataFrame(X_train_transformed, columns=transformed_col_names)\n",
    "X_train_transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSLE: 1.0127\n"
     ]
    }
   ],
   "source": [
    "preds = pipeline.predict(X_train)\n",
    "print(f\"Linear Regression RMSLE: {rmsle(log_y_train, preds, True):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuchie\\Desktop\\DataScience\\kaggle_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yuchie\\Desktop\\DataScience\\kaggle_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yuchie\\Desktop\\DataScience\\kaggle_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE scores:  [1.05722445 0.94580409 1.09784306 1.03996723 0.99754961]\n",
      "Mean RMSLE:  1.0276776875285407\n",
      "RMSLE standard deviation:  0.05207343002492441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuchie\\Desktop\\DataScience\\kaggle_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yuchie\\Desktop\\DataScience\\kaggle_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the custom scorer\n",
    "scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "# Add the scorer to the pipeline and perform cross-validation\n",
    "scores = -1 * cross_val_score(pipeline, X_train, log_y_train, cv=5, scoring=scorer)\n",
    "\n",
    "# Print the mean and standard deviation of the scores\n",
    "print(\"RMSLE scores: \", scores)\n",
    "print(\"Mean RMSLE: \", scores.mean())\n",
    "print(\"RMSLE standard deviation: \", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
