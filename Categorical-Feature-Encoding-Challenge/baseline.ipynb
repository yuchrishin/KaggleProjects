{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle - Categorical Feature Encoding Challenge - Baseline\n",
    "**Author: Chris Shin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', index_col='id')\n",
    "test = pd.read_csv('./data/test.csv', index_col='id')\n",
    "submission = pd.read_csv('./data/sample_submission.csv', index_col='id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering with train/test combined or separately?\n",
    "\n",
    "It is generally not recommended to perform feature engineering on the combined train and test data. This is because doing so can lead to data leakage, where the model inadvertently learns patterns or relationships between the features and the target variable that it should not have access to during training.\n",
    "\n",
    "Instead, it is recommended to perform feature engineering separately on the train and test data sets. This ensures that the model only learns patterns from the training data, and that the test data remains truly unseen until model evaluation.\n",
    "\n",
    "However, it is important to keep the feature engineering process consistent across both the train and test data sets, to ensure that the model can generalize well to new, unseen data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that train and test have the same columns after feature engineering, you can follow these steps:\n",
    "\n",
    "1. Perform all feature engineering steps on the train and test sets separately.\n",
    "2. Identify the columns that were created in the train set after feature engineering.\n",
    "3. Check if these columns exist in the test set after feature engineering. If a column does not exist in the test set, create that column in the test set with all zeros or some default value.\n",
    "4. Repeat steps 2-3 for any new columns that were created in the test set after feature engineering.\n",
    "5. Finally, reorder the columns in the test set to match the order of the columns in the train set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import sparse\n",
    "\n",
    "def feature_engineer(data):\n",
    "    df = data.copy()\n",
    "    # Binary Encoding\n",
    "    df['bin_3'] = df['bin_3'].map({'F':0, 'T':1})\n",
    "    df['bin_4'] = df['bin_4'].map({'N':0, 'Y':1})\n",
    "\n",
    "    # Ordinal Encoding\n",
    "    ord1dict = {'Novice':0, 'Contributor':1, \n",
    "            'Expert':2, 'Master':3, 'Grandmaster':4}\n",
    "    ord2dict = {'Freezing':0, 'Cold':1, 'Warm':2, \n",
    "                'Hot':3, 'Boiling Hot':4, 'Lava Hot':5}\n",
    "\n",
    "    df['ord_1'] = df['ord_1'].map(ord1dict)\n",
    "    df['ord_2'] = df['ord_2'].map(ord2dict)\n",
    "    ord_345 = ['ord_3', 'ord_4', 'ord_5']\n",
    "    ord_encoder = OrdinalEncoder()\n",
    "    df[ord_345] = ord_encoder.fit_transform(df[ord_345])\n",
    "\n",
    "    # Norminal Encoding\n",
    "    nom_features = ['nom_' + str(i) for i in range(6)]\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    encoded_nom_matrix = onehot_encoder.fit_transform(df[nom_features])\n",
    "    df = df.drop(['nom_' + str(i) for i in range(10)], axis=1)\n",
    "    \n",
    "    # Date Encoding\n",
    "    date_features  = ['day', 'month']\n",
    "    encoded_date_matrix = onehot_encoder.fit_transform(df[date_features])\n",
    "    df = df.drop(date_features, axis=1)\n",
    "    \n",
    "    # Ordinal features scaling\n",
    "    ord_features = ['ord_' + str(i) for i in range(6)]\n",
    "    df[ord_features] = MinMaxScaler().fit_transform(df[ord_features])\n",
    "    \n",
    "    df = sparse.hstack([sparse.csr_matrix(df),\n",
    "                                   encoded_nom_matrix,\n",
    "                                   encoded_date_matrix],\n",
    "                                   format='csr')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('target', axis=1)\n",
    "y_train = train['target']\n",
    "X_train = feature_engineer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<300000x277 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4297975 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                      test_size=0.1,\n",
    "                                                      stratify=y_train,\n",
    "                                                      random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'C': 0.125, 'max_iter': 800, 'random_state': 42, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "lr_params = {'C':[0.1, 0.125, 0.2], 'max_iter':[800, 900, 1000], \n",
    "             'solver':['liblinear'], 'random_state':[42]}\n",
    "\n",
    "gridsearch_logistic_model = GridSearchCV(estimator=logistic_model,\n",
    "                                         param_grid=lr_params,\n",
    "                                         scoring='roc_auc',\n",
    "                                         cv=5)\n",
    "gridsearch_logistic_model.fit(X_train, y_train)\n",
    "\n",
    "print('Optimal parameters:', gridsearch_logistic_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_preds = gridsearch_logistic_model.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data ROC AUC : 0.7795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "\n",
    "print(f'Validation data ROC AUC : {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = feature_engineer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200000x277 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2865743 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = gridsearch_logistic_model.best_estimator_.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission['target'] = y_preds\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
