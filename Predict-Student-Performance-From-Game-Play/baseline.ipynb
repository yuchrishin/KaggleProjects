{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "labels = pd.read_csv('./data/train_labels.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_fq_cols = ['historicalsociety_closet', 'historicalsociety_basement',\n",
    "       'historicalsociety_entry', 'historicalsociety_collection',\n",
    "       'historicalsociety_stacks', 'kohlcenter_halloffame',\n",
    "       'capitol_0_hall', 'historicalsociety_closet_dirty',\n",
    "       'historicalsociety_frontdesk', 'humanecology_frontdesk',\n",
    "       'drycleaner_frontdesk', 'library_frontdesk', 'library_microfiche',\n",
    "       'capitol_1_hall', 'historicalsociety_cage',\n",
    "       'historicalsociety_collection_flag', 'wildlife_center',\n",
    "       'flaghouse_entry', 'capitol_2_hall']\n",
    "\n",
    "def generate_elapsed_time_feature(df, df_merged):\n",
    "    temp = df.groupby(['session_id', 'event_name', 'level_group'])['elapsed_time'].agg(['sum']).reset_index()\n",
    "    temp = temp.rename(columns={'sum': 'elapsed_time'})\n",
    "    temp = temp.pivot(index='session_id', columns='event_name', values='elapsed_time')\n",
    "    temp.columns = [col + '_elapsed_time' for col in temp.columns]\n",
    "    temp = temp.reset_index()\n",
    "    df_merged = temp\n",
    "\n",
    "    temp = df.groupby(['session_id', 'room_fqid', 'level_group'])['elapsed_time'].agg(['sum']).reset_index()\n",
    "    temp = temp.rename(columns={'sum': 'elapsed_time'})\n",
    "    temp = temp.pivot(index='session_id', columns='room_fqid', values='elapsed_time')\n",
    "    temp.columns = [col + '_elapsed_time' for col in temp.columns]\n",
    "    temp = temp.reset_index()\n",
    "\n",
    "    df_merged = pd.merge(df_merged, temp, how='left', on='session_id')\n",
    "\n",
    "    for room_col in [col + '_elapsed_time' for col in room_fq_cols]:\n",
    "        if room_col not in df_merged.columns:\n",
    "            df_merged[room_col] = 0\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def generate_feature_counts(df, df_merged):\n",
    "    temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n",
    "    df_merged = pd.merge(df_merged, temp, how='left', on='session_id')\n",
    "\n",
    "    temp = df.groupby(['session_id', 'level'])['level'].agg(['count']).reset_index()\n",
    "    temp = temp.rename(columns={'count': 'level_counts'})\n",
    "    temp = temp.pivot(index='session_id', columns='level', values='level_counts')\n",
    "    temp.columns = ['level_' + str(col) + '_counts' for col in temp.columns]\n",
    "    temp = temp.reset_index()\n",
    "    df_merged = pd.merge(df_merged, temp, how='left', on='session_id')\n",
    "\n",
    "    temp = df.groupby(['session_id', 'event_name'])['event_name'].agg(['count']).reset_index()\n",
    "    temp = temp.rename(columns={'count': 'event_count'})\n",
    "    temp = temp.pivot(index='session_id', columns='event_name', values='event_count')\n",
    "    temp.columns = [col + '_counts' for col in temp.columns]\n",
    "    temp = temp.reset_index()\n",
    "\n",
    "    df_merged = pd.merge(df_merged, temp, how='left', on='session_id')\n",
    "    return df_merged\n",
    "\n",
    "def generate_notebook_feature(df, df_merged):\n",
    "    temp = df.groupby(['session_id', 'event_name', 'name'])['elapsed_time'].agg(['count']).reset_index()\n",
    "    temp = temp.rename(columns={'count': 'event_count'})\n",
    "    temp = temp[(temp['name'].isin(['open', 'prev', 'next']))]\n",
    "    temp = temp.pivot(index='session_id', columns='name', values='event_count')\n",
    "    temp.columns = ['notebook_' + col + '_counts' for col in temp.columns]\n",
    "    temp = temp.reset_index()\n",
    "    df_merged = pd.merge(df_merged, temp, how='left', on='session_id')\n",
    "\n",
    "    if 'notebook_open_counts' not in df_merged.columns:\n",
    "        df_merged['notebook_open_counts'] = 0\n",
    "    if 'notebook_prev_counts' not in df_merged.columns:\n",
    "        df_merged['notebook_prev_counts'] = 0\n",
    "    if 'notebook_next_counts' not in df_merged.columns:\n",
    "        df_merged['notebook_next_counts'] = 0\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def generate_hover_duration(df, df_merged):\n",
    "    temp = df.groupby(['session_id', 'event_name'])['hover_duration'].agg(['sum']).reset_index()\n",
    "    temp = temp.rename(columns={'sum': 'hover_duration'})\n",
    "    temp = temp[temp['hover_duration'] > 0]\n",
    "    temp = temp.pivot(index='session_id', columns='event_name', values='hover_duration')\n",
    "    temp.columns = [col + '_duration' for col in temp.columns]\n",
    "    temp = temp.reset_index()\n",
    "    df_merged = pd.merge(df_merged, temp, how='left', on='session_id')\n",
    "    return df_merged\n",
    "\n",
    "def generate_features(df, grp):\n",
    "    df_merged = pd.DataFrame()\n",
    "    df_merged = generate_elapsed_time_feature(df, df_merged)\n",
    "    df_merged = generate_feature_counts(df, df_merged)\n",
    "    df_merged = generate_notebook_feature(df, df_merged)\n",
    "    df_merged = generate_hover_duration(df, df_merged)\n",
    "    df_merged['level_group'] = grp\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def feature_engineering(df, grp):\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    col_use = ['session_id', 'elapsed_time', 'event_name', 'name', 'level',\n",
    "        'hover_duration', 'room_fqid', 'fullscreen', 'hq', 'music', 'level_group']\n",
    "\n",
    "    df = df[col_use]\n",
    "    \n",
    "    df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
    "\n",
    "    final_df = pd.concat([final_df, generate_features(df, grp)], ignore_index=True)\n",
    "\n",
    "    final_df.fillna(0, inplace=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\350501486.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['room_fqid'] = train['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\350501486.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  train['room_fqid'] = train['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['historicalsociety_closet', 'historicalsociety_basement',\n",
       "       'historicalsociety_entry', 'historicalsociety_collection',\n",
       "       'historicalsociety_stacks', 'kohlcenter_halloffame',\n",
       "       'capitol_0_hall', 'historicalsociety_closet_dirty',\n",
       "       'historicalsociety_frontdesk', 'humanecology_frontdesk',\n",
       "       'drycleaner_frontdesk', 'library_frontdesk', 'library_microfiche',\n",
       "       'capitol_1_hall', 'historicalsociety_cage',\n",
       "       'historicalsociety_collection_flag', 'wildlife_center',\n",
       "       'flaghouse_entry', 'capitol_2_hall'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['room_fqid'] = train['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
    "\n",
    "train['room_fqid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\1468210091.py:1: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  labels[['session_id', 'question_number']] = labels['session_id'].str.split('_', 1, expand=True)\n"
     ]
    }
   ],
   "source": [
    "labels[['session_id', 'question_number']] = labels['session_id'].str.split('_', 1, expand=True)\n",
    "labels['question_number'] = labels['question_number'].apply(lambda x: int(x[1:]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LightGBM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_lgb(preds, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    y_pred = np.round(preds)\n",
    "    return 'f1', f1_score(y_true, y_pred), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# We use stratifiedKFold since data is inbalance\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For baseline model simplified the parameter\n",
    "params = {'objective': 'binary',\n",
    "          'learning_rate': 0.01,\n",
    "          'force_row_wise': True,\n",
    "          'random_state': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_val_preds = {}\n",
    "# oof_test_preds = {}\n",
    "for i in range(1,19):\n",
    "    oof_val_preds[i] = np.zeros(int(train.shape[0] / 3))\n",
    "#     oof_test_preds[i] = np.zeros(int(test_df.shape[0] / 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training/predicting question 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13712, number of negative: 5137\n",
      "[LightGBM] [Info] Total Bins 6887\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.727466 -> initscore=0.981802\n",
      "[LightGBM] [Info] Start training from score 0.981802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.558215\tvalid_0's f1: 0.841768\n",
      "[200]\tvalid_0's binary_logloss: 0.549288\tvalid_0's f1: 0.84314\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's binary_logloss: 0.549793\tvalid_0's f1: 0.843649\n",
      "fold 1 f1 score : 0.8436490181456625\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13713, number of negative: 5136\n",
      "[LightGBM] [Info] Total Bins 6875\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.727519 -> initscore=0.982070\n",
      "[LightGBM] [Info] Start training from score 0.982070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.5547\tvalid_0's f1: 0.842222\n",
      "[200]\tvalid_0's binary_logloss: 0.544759\tvalid_0's f1: 0.843925\n",
      "[300]\tvalid_0's binary_logloss: 0.540019\tvalid_0's f1: 0.843413\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's binary_logloss: 0.542722\tvalid_0's f1: 0.844472\n",
      "fold 2 f1 score : 0.8444722048719551\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13713, number of negative: 5137\n",
      "[LightGBM] [Info] Total Bins 6878\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.727480 -> initscore=0.981875\n",
      "[LightGBM] [Info] Start training from score 0.981875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.557924\tvalid_0's f1: 0.842468\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.558473\tvalid_0's f1: 0.842753\n",
      "fold 3 f1 score : 0.8427533554980914\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13713, number of negative: 5137\n",
      "[LightGBM] [Info] Total Bins 6887\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.727480 -> initscore=0.981875\n",
      "[LightGBM] [Info] Start training from score 0.981875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.556613\tvalid_0's f1: 0.842688\n",
      "[200]\tvalid_0's binary_logloss: 0.546921\tvalid_0's f1: 0.842276\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.551368\tvalid_0's f1: 0.844934\n",
      "fold 4 f1 score : 0.8449343571959376\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13713, number of negative: 5137\n",
      "[LightGBM] [Info] Total Bins 6886\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.727480 -> initscore=0.981875\n",
      "[LightGBM] [Info] Start training from score 0.981875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.557004\tvalid_0's f1: 0.842947\n",
      "[200]\tvalid_0's binary_logloss: 0.549045\tvalid_0's f1: 0.843074\n",
      "[300]\tvalid_0's binary_logloss: 0.545287\tvalid_0's f1: 0.843495\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's binary_logloss: 0.545976\tvalid_0's f1: 0.844506\n",
      "fold 5 f1 score : 0.8445057010399698\n",
      "\n",
      "training/predicting question 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 18450, number of negative: 399\n",
      "[LightGBM] [Info] Total Bins 6872\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.978832 -> initscore=3.833858\n",
      "[LightGBM] [Info] Start training from score 3.833858\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0953564\tvalid_0's f1: 0.989277\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.10255\tvalid_0's f1: 0.989277\n",
      "fold 1 f1 score : 0.9892772892987347\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 18450, number of negative: 399\n",
      "[LightGBM] [Info] Total Bins 6880\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.978832 -> initscore=3.833858\n",
      "[LightGBM] [Info] Start training from score 3.833858\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0977975\tvalid_0's f1: 0.989277\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.10254\tvalid_0's f1: 0.989277\n",
      "fold 2 f1 score : 0.9892772892987347\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 18450, number of negative: 400\n",
      "[LightGBM] [Info] Total Bins 6879\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.978780 -> initscore=3.831355\n",
      "[LightGBM] [Info] Start training from score 3.831355\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0966567\tvalid_0's f1: 0.989383\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.101737\tvalid_0's f1: 0.989383\n",
      "fold 3 f1 score : 0.9893833780160858\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 18451, number of negative: 399\n",
      "[LightGBM] [Info] Total Bins 6888\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.978833 -> initscore=3.833912\n",
      "[LightGBM] [Info] Start training from score 3.833912\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0973378\tvalid_0's f1: 0.989275\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.102501\tvalid_0's f1: 0.989275\n",
      "fold 4 f1 score : 0.9892749892749894\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 18451, number of negative: 399\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.978833 -> initscore=3.833912\n",
      "[LightGBM] [Info] Start training from score 3.833912\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0981547\tvalid_0's f1: 0.989275\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.102594\tvalid_0's f1: 0.989275\n",
      "fold 5 f1 score : 0.9892749892749894\n",
      "\n",
      "training/predicting question 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17605, number of negative: 1244\n",
      "[LightGBM] [Info] Total Bins 6884\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.934002 -> initscore=2.649851\n",
      "[LightGBM] [Info] Start training from score 2.649851\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.232789\tvalid_0's f1: 0.96588\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.242812\tvalid_0's f1: 0.96588\n",
      "fold 1 f1 score : 0.9658804168952276\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17605, number of negative: 1244\n",
      "[LightGBM] [Info] Total Bins 6886\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.934002 -> initscore=2.649851\n",
      "[LightGBM] [Info] Start training from score 2.649851\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.236149\tvalid_0's f1: 0.96588\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.242881\tvalid_0's f1: 0.96588\n",
      "fold 2 f1 score : 0.9658804168952276\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17606, number of negative: 1244\n",
      "[LightGBM] [Info] Total Bins 6881\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.934005 -> initscore=2.649908\n",
      "[LightGBM] [Info] Start training from score 2.649908\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.231239\tvalid_0's f1: 0.965873\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.242914\tvalid_0's f1: 0.965873\n",
      "fold 3 f1 score : 0.9658729287830572\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17606, number of negative: 1244\n",
      "[LightGBM] [Info] Total Bins 6880\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.934005 -> initscore=2.649908\n",
      "[LightGBM] [Info] Start training from score 2.649908\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.230728\tvalid_0's f1: 0.965873\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.242876\tvalid_0's f1: 0.965873\n",
      "fold 4 f1 score : 0.9658729287830572\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17606, number of negative: 1244\n",
      "[LightGBM] [Info] Total Bins 6880\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.934005 -> initscore=2.649908\n",
      "[LightGBM] [Info] Start training from score 2.649908\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.231242\tvalid_0's f1: 0.965873\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.242891\tvalid_0's f1: 0.965873\n",
      "fold 5 f1 score : 0.9658729287830572\n",
      "\n",
      "training/predicting question 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 15046, number of negative: 3803\n",
      "[LightGBM] [Info] Total Bins 9757\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798239 -> initscore=1.375322\n",
      "[LightGBM] [Info] Start training from score 1.375322\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.457691\tvalid_0's f1: 0.889573\n",
      "[200]\tvalid_0's binary_logloss: 0.446111\tvalid_0's f1: 0.892627\n",
      "[300]\tvalid_0's binary_logloss: 0.441489\tvalid_0's f1: 0.893643\n",
      "[400]\tvalid_0's binary_logloss: 0.439814\tvalid_0's f1: 0.893874\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's binary_logloss: 0.44062\tvalid_0's f1: 0.894452\n",
      "fold 1 f1 score : 0.8944517992538211\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 15046, number of negative: 3803\n",
      "[LightGBM] [Info] Total Bins 9748\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798239 -> initscore=1.375322\n",
      "[LightGBM] [Info] Start training from score 1.375322\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.46731\tvalid_0's f1: 0.8896\n",
      "[200]\tvalid_0's binary_logloss: 0.459529\tvalid_0's f1: 0.88934\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's binary_logloss: 0.466777\tvalid_0's f1: 0.890127\n",
      "fold 2 f1 score : 0.8901268223302121\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 15046, number of negative: 3804\n",
      "[LightGBM] [Info] Total Bins 9764\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798196 -> initscore=1.375059\n",
      "[LightGBM] [Info] Start training from score 1.375059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.463004\tvalid_0's f1: 0.889204\n",
      "[200]\tvalid_0's binary_logloss: 0.454178\tvalid_0's f1: 0.891414\n",
      "[300]\tvalid_0's binary_logloss: 0.451027\tvalid_0's f1: 0.890625\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's binary_logloss: 0.45281\tvalid_0's f1: 0.89195\n",
      "fold 3 f1 score : 0.8919501677048396\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 15047, number of negative: 3803\n",
      "[LightGBM] [Info] Total Bins 9760\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798249 -> initscore=1.375388\n",
      "[LightGBM] [Info] Start training from score 1.375388\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.464859\tvalid_0's f1: 0.88881\n",
      "[200]\tvalid_0's binary_logloss: 0.457416\tvalid_0's f1: 0.88857\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.464002\tvalid_0's f1: 0.889126\n",
      "fold 4 f1 score : 0.8891255472725121\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 15047, number of negative: 3803\n",
      "[LightGBM] [Info] Total Bins 9753\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798249 -> initscore=1.375388\n",
      "[LightGBM] [Info] Start training from score 1.375388\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.46161\tvalid_0's f1: 0.889257\n",
      "[200]\tvalid_0's binary_logloss: 0.451973\tvalid_0's f1: 0.890349\n",
      "[300]\tvalid_0's binary_logloss: 0.447836\tvalid_0's f1: 0.889718\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.450735\tvalid_0's f1: 0.89139\n",
      "fold 5 f1 score : 0.8913902526643516\n",
      "\n",
      "training/predicting question 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 10334, number of negative: 8515\n",
      "[LightGBM] [Info] Total Bins 9766\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.548252 -> initscore=0.193610\n",
      "[LightGBM] [Info] Start training from score 0.193610\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.656123\tvalid_0's f1: 0.690989\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's binary_logloss: 0.675876\tvalid_0's f1: 0.713812\n",
      "fold 1 f1 score : 0.7138124729943828\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 10334, number of negative: 8515\n",
      "[LightGBM] [Info] Total Bins 9751\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.548252 -> initscore=0.193610\n",
      "[LightGBM] [Info] Start training from score 0.193610\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.652517\tvalid_0's f1: 0.701259\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's binary_logloss: 0.67233\tvalid_0's f1: 0.717717\n",
      "fold 2 f1 score : 0.7177172805357404\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 10334, number of negative: 8516\n",
      "[LightGBM] [Info] Total Bins 9770\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.548223 -> initscore=0.193493\n",
      "[LightGBM] [Info] Start training from score 0.193493\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.654045\tvalid_0's f1: 0.707672\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's binary_logloss: 0.675032\tvalid_0's f1: 0.718911\n",
      "fold 3 f1 score : 0.7189111747851004\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 10335, number of negative: 8515\n",
      "[LightGBM] [Info] Total Bins 9754\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.548276 -> initscore=0.193707\n",
      "[LightGBM] [Info] Start training from score 0.193707\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.652734\tvalid_0's f1: 0.705443\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's binary_logloss: 0.672205\tvalid_0's f1: 0.723677\n",
      "fold 4 f1 score : 0.7236765561372892\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 10335, number of negative: 8515\n",
      "[LightGBM] [Info] Total Bins 9751\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.548276 -> initscore=0.193707\n",
      "[LightGBM] [Info] Start training from score 0.193707\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.652611\tvalid_0's f1: 0.703201\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's binary_logloss: 0.670313\tvalid_0's f1: 0.721432\n",
      "fold 5 f1 score : 0.7214317148305706\n",
      "\n",
      "training/predicting question 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 14626, number of negative: 4223\n",
      "[LightGBM] [Info] Total Bins 9767\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.775956 -> initscore=1.242255\n",
      "[LightGBM] [Info] Start training from score 1.242255\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.495927\tvalid_0's f1: 0.874102\n",
      "[200]\tvalid_0's binary_logloss: 0.490025\tvalid_0's f1: 0.876555\n",
      "[300]\tvalid_0's binary_logloss: 0.488887\tvalid_0's f1: 0.876457\n",
      "Early stopping, best iteration is:\n",
      "[274]\tvalid_0's binary_logloss: 0.489116\tvalid_0's f1: 0.877098\n",
      "fold 1 f1 score : 0.8770983948045583\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 14626, number of negative: 4223\n",
      "[LightGBM] [Info] Total Bins 9757\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.775956 -> initscore=1.242255\n",
      "[LightGBM] [Info] Start training from score 1.242255\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.498039\tvalid_0's f1: 0.87358\n",
      "[200]\tvalid_0's binary_logloss: 0.493218\tvalid_0's f1: 0.875259\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.495545\tvalid_0's f1: 0.875737\n",
      "fold 2 f1 score : 0.8757367977865993\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 14626, number of negative: 4224\n",
      "[LightGBM] [Info] Total Bins 9709\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.775915 -> initscore=1.242018\n",
      "[LightGBM] [Info] Start training from score 1.242018\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.498323\tvalid_0's f1: 0.874446\n",
      "[200]\tvalid_0's binary_logloss: 0.492536\tvalid_0's f1: 0.872554\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.498196\tvalid_0's f1: 0.874521\n",
      "fold 3 f1 score : 0.8745210727969349\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 14627, number of negative: 4223\n",
      "[LightGBM] [Info] Total Bins 9770\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.775968 -> initscore=1.242323\n",
      "[LightGBM] [Info] Start training from score 1.242323\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.49926\tvalid_0's f1: 0.873216\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's binary_logloss: 0.499959\tvalid_0's f1: 0.874641\n",
      "fold 4 f1 score : 0.8746411483253589\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 14627, number of negative: 4223\n",
      "[LightGBM] [Info] Total Bins 9709\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.775968 -> initscore=1.242323\n",
      "[LightGBM] [Info] Start training from score 1.242323\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.494199\tvalid_0's f1: 0.874014\n",
      "[200]\tvalid_0's binary_logloss: 0.487355\tvalid_0's f1: 0.87585\n",
      "[300]\tvalid_0's binary_logloss: 0.485698\tvalid_0's f1: 0.874679\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's binary_logloss: 0.486808\tvalid_0's f1: 0.876172\n",
      "fold 5 f1 score : 0.8761719225617922\n",
      "\n",
      "training/predicting question 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13874, number of negative: 4975\n",
      "[LightGBM] [Info] Total Bins 9698\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736060 -> initscore=1.025591\n",
      "[LightGBM] [Info] Start training from score 1.025591\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.550699\tvalid_0's f1: 0.847818\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.576562\tvalid_0's f1: 0.847959\n",
      "fold 1 f1 score : 0.8479589342459056\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13874, number of negative: 4975\n",
      "[LightGBM] [Info] Total Bins 9765\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736060 -> initscore=1.025591\n",
      "[LightGBM] [Info] Start training from score 1.025591\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.551974\tvalid_0's f1: 0.848025\n",
      "[200]\tvalid_0's binary_logloss: 0.546699\tvalid_0's f1: 0.846421\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.549283\tvalid_0's f1: 0.848841\n",
      "fold 2 f1 score : 0.8488414858403825\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13874, number of negative: 4976\n",
      "[LightGBM] [Info] Total Bins 9758\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736021 -> initscore=1.025390\n",
      "[LightGBM] [Info] Start training from score 1.025390\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.552839\tvalid_0's f1: 0.848063\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.576437\tvalid_0's f1: 0.848063\n",
      "fold 3 f1 score : 0.8480625840361814\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13875, number of negative: 4975\n",
      "[LightGBM] [Info] Total Bins 9758\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736074 -> initscore=1.025663\n",
      "[LightGBM] [Info] Start training from score 1.025663\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.554172\tvalid_0's f1: 0.84844\n",
      "[200]\tvalid_0's binary_logloss: 0.549695\tvalid_0's f1: 0.846594\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's binary_logloss: 0.553298\tvalid_0's f1: 0.84847\n",
      "fold 4 f1 score : 0.848470012239902\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13875, number of negative: 4975\n",
      "[LightGBM] [Info] Total Bins 9759\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736074 -> initscore=1.025663\n",
      "[LightGBM] [Info] Start training from score 1.025663\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.551852\tvalid_0's f1: 0.848025\n",
      "[200]\tvalid_0's binary_logloss: 0.547373\tvalid_0's f1: 0.84698\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.549209\tvalid_0's f1: 0.84899\n",
      "fold 5 f1 score : 0.8489895897121861\n",
      "\n",
      "training/predicting question 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 11634, number of negative: 7215\n",
      "[LightGBM] [Info] Total Bins 9763\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.617221 -> initscore=0.477770\n",
      "[LightGBM] [Info] Start training from score 0.477770\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.654085\tvalid_0's f1: 0.765901\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's binary_logloss: 0.654246\tvalid_0's f1: 0.766291\n",
      "fold 1 f1 score : 0.7662906436629064\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 11634, number of negative: 7215\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.617221 -> initscore=0.477770\n",
      "[LightGBM] [Info] Start training from score 0.477770\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.656799\tvalid_0's f1: 0.762031\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.658607\tvalid_0's f1: 0.764063\n",
      "fold 2 f1 score : 0.7640627058358582\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 11634, number of negative: 7216\n",
      "[LightGBM] [Info] Total Bins 9751\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.617188 -> initscore=0.477631\n",
      "[LightGBM] [Info] Start training from score 0.477631\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.654442\tvalid_0's f1: 0.76423\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.654795\tvalid_0's f1: 0.764503\n",
      "fold 3 f1 score : 0.7645033112582781\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 11635, number of negative: 7215\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.617241 -> initscore=0.477856\n",
      "[LightGBM] [Info] Start training from score 0.477856\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.65691\tvalid_0's f1: 0.762184\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.658844\tvalid_0's f1: 0.764288\n",
      "fold 4 f1 score : 0.764287595470108\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 11635, number of negative: 7215\n",
      "[LightGBM] [Info] Total Bins 9760\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.617241 -> initscore=0.477856\n",
      "[LightGBM] [Info] Start training from score 0.477856\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.655388\tvalid_0's f1: 0.763095\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's binary_logloss: 0.65833\tvalid_0's f1: 0.764009\n",
      "fold 5 f1 score : 0.7640094711917916\n",
      "\n",
      "training/predicting question 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13878, number of negative: 4971\n",
      "[LightGBM] [Info] Total Bins 9754\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736272 -> initscore=1.026684\n",
      "[LightGBM] [Info] Start training from score 1.026684\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.548304\tvalid_0's f1: 0.849147\n",
      "[200]\tvalid_0's binary_logloss: 0.543166\tvalid_0's f1: 0.850392\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.544598\tvalid_0's f1: 0.851122\n",
      "fold 1 f1 score : 0.8511218544688236\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13878, number of negative: 4971\n",
      "[LightGBM] [Info] Total Bins 9752\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736272 -> initscore=1.026684\n",
      "[LightGBM] [Info] Start training from score 1.026684\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.546226\tvalid_0's f1: 0.851446\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.546476\tvalid_0's f1: 0.851587\n",
      "fold 2 f1 score : 0.8515874969234555\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13878, number of negative: 4972\n",
      "[LightGBM] [Info] Total Bins 9760\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736233 -> initscore=1.026483\n",
      "[LightGBM] [Info] Start training from score 1.026483\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.54736\tvalid_0's f1: 0.849073\n",
      "[200]\tvalid_0's binary_logloss: 0.540965\tvalid_0's f1: 0.851663\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's binary_logloss: 0.541073\tvalid_0's f1: 0.851806\n",
      "fold 3 f1 score : 0.8518057285180572\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13879, number of negative: 4971\n",
      "[LightGBM] [Info] Total Bins 9751\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736286 -> initscore=1.026756\n",
      "[LightGBM] [Info] Start training from score 1.026756\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.546582\tvalid_0's f1: 0.849982\n",
      "[200]\tvalid_0's binary_logloss: 0.541194\tvalid_0's f1: 0.852004\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's binary_logloss: 0.541996\tvalid_0's f1: 0.852304\n",
      "fold 4 f1 score : 0.8523038605230387\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13879, number of negative: 4971\n",
      "[LightGBM] [Info] Total Bins 9758\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.736286 -> initscore=1.026756\n",
      "[LightGBM] [Info] Start training from score 1.026756\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.550424\tvalid_0's f1: 0.848738\n",
      "[200]\tvalid_0's binary_logloss: 0.545318\tvalid_0's f1: 0.849551\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.54679\tvalid_0's f1: 0.850378\n",
      "fold 5 f1 score : 0.8503780835502665\n",
      "\n",
      "training/predicting question 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9527, number of negative: 9322\n",
      "[LightGBM] [Info] Total Bins 9754\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505438 -> initscore=0.021753\n",
      "[LightGBM] [Info] Start training from score 0.021753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.660749\tvalid_0's f1: 0.646581\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.691044\tvalid_0's f1: 0.682488\n",
      "fold 1 f1 score : 0.682487978904917\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9527, number of negative: 9322\n",
      "[LightGBM] [Info] Total Bins 9717\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505438 -> initscore=0.021753\n",
      "[LightGBM] [Info] Start training from score 0.021753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.664286\tvalid_0's f1: 0.637089\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.691247\tvalid_0's f1: 0.681336\n",
      "fold 2 f1 score : 0.6813355900907831\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9527, number of negative: 9323\n",
      "[LightGBM] [Info] Total Bins 9757\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505411 -> initscore=0.021645\n",
      "[LightGBM] [Info] Start training from score 0.021645\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.663858\tvalid_0's f1: 0.629615\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.691261\tvalid_0's f1: 0.682609\n",
      "fold 3 f1 score : 0.6826086956521739\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9527, number of negative: 9323\n",
      "[LightGBM] [Info] Total Bins 9755\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505411 -> initscore=0.021645\n",
      "[LightGBM] [Info] Start training from score 0.021645\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.665758\tvalid_0's f1: 0.625223\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.691187\tvalid_0's f1: 0.681643\n",
      "fold 4 f1 score : 0.6816433297430374\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9528, number of negative: 9322\n",
      "[LightGBM] [Info] Total Bins 9762\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505464 -> initscore=0.021858\n",
      "[LightGBM] [Info] Start training from score 0.021858\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.66318\tvalid_0's f1: 0.632971\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.69183\tvalid_0's f1: 0.681913\n",
      "fold 5 f1 score : 0.681912681912682\n",
      "\n",
      "training/predicting question 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12132, number of negative: 6717\n",
      "[LightGBM] [Info] Total Bins 9751\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.643642 -> initscore=0.591205\n",
      "[LightGBM] [Info] Start training from score 0.591205\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.633066\tvalid_0's f1: 0.784329\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's binary_logloss: 0.634625\tvalid_0's f1: 0.785649\n",
      "fold 1 f1 score : 0.7856490541422049\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12132, number of negative: 6717\n",
      "[LightGBM] [Info] Total Bins 9753\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.643642 -> initscore=0.591205\n",
      "[LightGBM] [Info] Start training from score 0.591205\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.632994\tvalid_0's f1: 0.783193\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.635966\tvalid_0's f1: 0.784304\n",
      "fold 2 f1 score : 0.7843035343035343\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12132, number of negative: 6718\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.643607 -> initscore=0.591056\n",
      "[LightGBM] [Info] Start training from score 0.591056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.630996\tvalid_0's f1: 0.78451\n",
      "[200]\tvalid_0's binary_logloss: 0.626494\tvalid_0's f1: 0.783322\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.627395\tvalid_0's f1: 0.786024\n",
      "fold 3 f1 score : 0.78602383531961\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12132, number of negative: 6718\n",
      "[LightGBM] [Info] Total Bins 9759\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.643607 -> initscore=0.591056\n",
      "[LightGBM] [Info] Start training from score 0.591056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.634676\tvalid_0's f1: 0.78378\n",
      "[200]\tvalid_0's binary_logloss: 0.632148\tvalid_0's f1: 0.776242\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.634494\tvalid_0's f1: 0.784334\n",
      "fold 4 f1 score : 0.7843344800211696\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12132, number of negative: 6718\n",
      "[LightGBM] [Info] Total Bins 9752\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.643607 -> initscore=0.591056\n",
      "[LightGBM] [Info] Start training from score 0.591056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.632753\tvalid_0's f1: 0.783562\n",
      "[200]\tvalid_0's binary_logloss: 0.629983\tvalid_0's f1: 0.779217\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.631488\tvalid_0's f1: 0.784695\n",
      "fold 5 f1 score : 0.7846953739501401\n",
      "\n",
      "training/predicting question 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 16266, number of negative: 2583\n",
      "[LightGBM] [Info] Total Bins 9753\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.862964 -> initscore=1.840126\n",
      "[LightGBM] [Info] Start training from score 1.840126\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.387878\tvalid_0's f1: 0.926424\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.399345\tvalid_0's f1: 0.926424\n",
      "fold 1 f1 score : 0.9264236902050114\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 16266, number of negative: 2583\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.862964 -> initscore=1.840126\n",
      "[LightGBM] [Info] Start training from score 1.840126\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.387751\tvalid_0's f1: 0.926424\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.399263\tvalid_0's f1: 0.926424\n",
      "fold 2 f1 score : 0.9264236902050114\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 16266, number of negative: 2584\n",
      "[LightGBM] [Info] Total Bins 9743\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.862918 -> initscore=1.839738\n",
      "[LightGBM] [Info] Start training from score 1.839738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.388388\tvalid_0's f1: 0.926529\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.398973\tvalid_0's f1: 0.926529\n",
      "fold 3 f1 score : 0.9265292174507347\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 16267, number of negative: 2583\n",
      "[LightGBM] [Info] Total Bins 9761\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.862971 -> initscore=1.840187\n",
      "[LightGBM] [Info] Start training from score 1.840187\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.38579\tvalid_0's f1: 0.926407\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.399341\tvalid_0's f1: 0.926407\n",
      "fold 4 f1 score : 0.9264069264069265\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 16267, number of negative: 2583\n",
      "[LightGBM] [Info] Total Bins 9761\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.862971 -> initscore=1.840187\n",
      "[LightGBM] [Info] Start training from score 1.840187\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.389651\tvalid_0's f1: 0.926407\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.399458\tvalid_0's f1: 0.926407\n",
      "fold 5 f1 score : 0.9264069264069265\n",
      "\n",
      "training/predicting question 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 5185, number of negative: 13664\n",
      "[LightGBM] [Info] Total Bins 9755\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.275081 -> initscore=-0.968995\n",
      "[LightGBM] [Info] Start training from score -0.968995\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.556703\tvalid_0's f1: 0.0197869\n",
      "[200]\tvalid_0's binary_logloss: 0.550579\tvalid_0's f1: 0.0877067\n",
      "[300]\tvalid_0's binary_logloss: 0.548914\tvalid_0's f1: 0.127248\n",
      "[400]\tvalid_0's binary_logloss: 0.548084\tvalid_0's f1: 0.145847\n",
      "[500]\tvalid_0's binary_logloss: 0.548121\tvalid_0's f1: 0.163782\n",
      "Early stopping, best iteration is:\n",
      "[483]\tvalid_0's binary_logloss: 0.548021\tvalid_0's f1: 0.162775\n",
      "fold 1 f1 score : 0.1627751834556371\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 5185, number of negative: 13664\n",
      "[LightGBM] [Info] Total Bins 9753\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.275081 -> initscore=-0.968995\n",
      "[LightGBM] [Info] Start training from score -0.968995\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.557602\tvalid_0's f1: 0.0316742\n",
      "[200]\tvalid_0's binary_logloss: 0.553398\tvalid_0's f1: 0.124389\n",
      "[300]\tvalid_0's binary_logloss: 0.553427\tvalid_0's f1: 0.177955\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.553201\tvalid_0's f1: 0.141776\n",
      "fold 2 f1 score : 0.14177563661390227\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 5186, number of negative: 13664\n",
      "[LightGBM] [Info] Total Bins 9750\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.275119 -> initscore=-0.968802\n",
      "[LightGBM] [Info] Start training from score -0.968802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.559304\tvalid_0's f1: 0.0152091\n",
      "[200]\tvalid_0's binary_logloss: 0.553743\tvalid_0's f1: 0.111188\n",
      "[300]\tvalid_0's binary_logloss: 0.552748\tvalid_0's f1: 0.147606\n",
      "[400]\tvalid_0's binary_logloss: 0.552703\tvalid_0's f1: 0.161774\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid_0's binary_logloss: 0.552451\tvalid_0's f1: 0.155468\n",
      "fold 3 f1 score : 0.155467720685112\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 5186, number of negative: 13664\n",
      "[LightGBM] [Info] Total Bins 9749\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.275119 -> initscore=-0.968802\n",
      "[LightGBM] [Info] Start training from score -0.968802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.554263\tvalid_0's f1: 0.0213252\n",
      "[200]\tvalid_0's binary_logloss: 0.54725\tvalid_0's f1: 0.11056\n",
      "[300]\tvalid_0's binary_logloss: 0.545402\tvalid_0's f1: 0.150203\n",
      "[400]\tvalid_0's binary_logloss: 0.545409\tvalid_0's f1: 0.161011\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid_0's binary_logloss: 0.545252\tvalid_0's f1: 0.153329\n",
      "fold 4 f1 score : 0.15332885003362476\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 5186, number of negative: 13664\n",
      "[LightGBM] [Info] Total Bins 9764\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.275119 -> initscore=-0.968802\n",
      "[LightGBM] [Info] Start training from score -0.968802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.55856\tvalid_0's f1: 0.036036\n",
      "[200]\tvalid_0's binary_logloss: 0.553563\tvalid_0's f1: 0.121045\n",
      "[300]\tvalid_0's binary_logloss: 0.552818\tvalid_0's f1: 0.148541\n",
      "[400]\tvalid_0's binary_logloss: 0.552712\tvalid_0's f1: 0.168831\n",
      "[500]\tvalid_0's binary_logloss: 0.55267\tvalid_0's f1: 0.184734\n",
      "Early stopping, best iteration is:\n",
      "[431]\tvalid_0's binary_logloss: 0.55254\tvalid_0's f1: 0.171206\n",
      "fold 5 f1 score : 0.17120622568093385\n",
      "\n",
      "training/predicting question 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13339, number of negative: 5510\n",
      "[LightGBM] [Info] Total Bins 11651\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.707677 -> initscore=0.884127\n",
      "[LightGBM] [Info] Start training from score 0.884127\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.577364\tvalid_0's f1: 0.830089\n",
      "[200]\tvalid_0's binary_logloss: 0.57141\tvalid_0's f1: 0.828776\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.575484\tvalid_0's f1: 0.831126\n",
      "fold 1 f1 score : 0.831126245428175\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13339, number of negative: 5510\n",
      "[LightGBM] [Info] Total Bins 11633\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.707677 -> initscore=0.884127\n",
      "[LightGBM] [Info] Start training from score 0.884127\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.57485\tvalid_0's f1: 0.83128\n",
      "[200]\tvalid_0's binary_logloss: 0.568632\tvalid_0's f1: 0.831375\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's binary_logloss: 0.570706\tvalid_0's f1: 0.832995\n",
      "fold 2 f1 score : 0.8329949238578681\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13339, number of negative: 5511\n",
      "[LightGBM] [Info] Total Bins 11628\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.707639 -> initscore=0.883946\n",
      "[LightGBM] [Info] Start training from score 0.883946\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.570962\tvalid_0's f1: 0.831845\n",
      "[200]\tvalid_0's binary_logloss: 0.563699\tvalid_0's f1: 0.834273\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.566055\tvalid_0's f1: 0.834924\n",
      "fold 3 f1 score : 0.834924271350388\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13339, number of negative: 5511\n",
      "[LightGBM] [Info] Total Bins 11634\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.707639 -> initscore=0.883946\n",
      "[LightGBM] [Info] Start training from score 0.883946\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.572311\tvalid_0's f1: 0.832347\n",
      "[200]\tvalid_0's binary_logloss: 0.564881\tvalid_0's f1: 0.83043\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.572311\tvalid_0's f1: 0.832347\n",
      "fold 4 f1 score : 0.8323466431540495\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13340, number of negative: 5510\n",
      "[LightGBM] [Info] Total Bins 11632\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.707692 -> initscore=0.884202\n",
      "[LightGBM] [Info] Start training from score 0.884202\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.574044\tvalid_0's f1: 0.831325\n",
      "[200]\tvalid_0's binary_logloss: 0.566465\tvalid_0's f1: 0.831625\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's binary_logloss: 0.571555\tvalid_0's f1: 0.833817\n",
      "fold 5 f1 score : 0.8338170347003155\n",
      "\n",
      "training/predicting question 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9067, number of negative: 9782\n",
      "[LightGBM] [Info] Total Bins 11633\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481033 -> initscore=-0.075903\n",
      "[LightGBM] [Info] Start training from score -0.075903\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.658875\tvalid_0's f1: 0.593382\n",
      "[200]\tvalid_0's binary_logloss: 0.651256\tvalid_0's f1: 0.605612\n",
      "[300]\tvalid_0's binary_logloss: 0.649021\tvalid_0's f1: 0.608883\n",
      "[400]\tvalid_0's binary_logloss: 0.648561\tvalid_0's f1: 0.611279\n",
      "[500]\tvalid_0's binary_logloss: 0.64881\tvalid_0's f1: 0.613798\n",
      "Early stopping, best iteration is:\n",
      "[409]\tvalid_0's binary_logloss: 0.648538\tvalid_0's f1: 0.612403\n",
      "fold 1 f1 score : 0.6124031007751939\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9067, number of negative: 9782\n",
      "[LightGBM] [Info] Total Bins 11645\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481033 -> initscore=-0.075903\n",
      "[LightGBM] [Info] Start training from score -0.075903\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.657666\tvalid_0's f1: 0.61488\n",
      "[200]\tvalid_0's binary_logloss: 0.649313\tvalid_0's f1: 0.617539\n",
      "[300]\tvalid_0's binary_logloss: 0.646326\tvalid_0's f1: 0.624092\n",
      "[400]\tvalid_0's binary_logloss: 0.645366\tvalid_0's f1: 0.626224\n",
      "Early stopping, best iteration is:\n",
      "[391]\tvalid_0's binary_logloss: 0.645431\tvalid_0's f1: 0.628243\n",
      "fold 2 f1 score : 0.6282433007230964\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9067, number of negative: 9783\n",
      "[LightGBM] [Info] Total Bins 11644\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481008 -> initscore=-0.076005\n",
      "[LightGBM] [Info] Start training from score -0.076005\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.657196\tvalid_0's f1: 0.596774\n",
      "[200]\tvalid_0's binary_logloss: 0.64833\tvalid_0's f1: 0.608259\n",
      "[300]\tvalid_0's binary_logloss: 0.645504\tvalid_0's f1: 0.608866\n",
      "[400]\tvalid_0's binary_logloss: 0.64447\tvalid_0's f1: 0.613078\n",
      "[500]\tvalid_0's binary_logloss: 0.643714\tvalid_0's f1: 0.613577\n",
      "[600]\tvalid_0's binary_logloss: 0.643721\tvalid_0's f1: 0.611862\n",
      "Early stopping, best iteration is:\n",
      "[518]\tvalid_0's binary_logloss: 0.643661\tvalid_0's f1: 0.615318\n",
      "fold 3 f1 score : 0.6153176675369886\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9067, number of negative: 9783\n",
      "[LightGBM] [Info] Total Bins 11612\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481008 -> initscore=-0.076005\n",
      "[LightGBM] [Info] Start training from score -0.076005\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.656214\tvalid_0's f1: 0.598842\n",
      "[200]\tvalid_0's binary_logloss: 0.647199\tvalid_0's f1: 0.610118\n",
      "[300]\tvalid_0's binary_logloss: 0.643983\tvalid_0's f1: 0.612076\n",
      "[400]\tvalid_0's binary_logloss: 0.642863\tvalid_0's f1: 0.614286\n",
      "[500]\tvalid_0's binary_logloss: 0.641939\tvalid_0's f1: 0.616551\n",
      "[600]\tvalid_0's binary_logloss: 0.641778\tvalid_0's f1: 0.616415\n",
      "Early stopping, best iteration is:\n",
      "[563]\tvalid_0's binary_logloss: 0.641671\tvalid_0's f1: 0.619037\n",
      "fold 4 f1 score : 0.619037340815886\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 9068, number of negative: 9782\n",
      "[LightGBM] [Info] Total Bins 11629\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481061 -> initscore=-0.075792\n",
      "[LightGBM] [Info] Start training from score -0.075792\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.658363\tvalid_0's f1: 0.593624\n",
      "[200]\tvalid_0's binary_logloss: 0.649447\tvalid_0's f1: 0.607955\n",
      "[300]\tvalid_0's binary_logloss: 0.646732\tvalid_0's f1: 0.61244\n",
      "[400]\tvalid_0's binary_logloss: 0.645896\tvalid_0's f1: 0.611026\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's binary_logloss: 0.645932\tvalid_0's f1: 0.613444\n",
      "fold 5 f1 score : 0.6134435501413966\n",
      "\n",
      "training/predicting question 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13852, number of negative: 4997\n",
      "[LightGBM] [Info] Total Bins 11637\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734893 -> initscore=1.019592\n",
      "[LightGBM] [Info] Start training from score 1.019592\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.576711\tvalid_0's f1: 0.847114\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.578356\tvalid_0's f1: 0.847114\n",
      "fold 1 f1 score : 0.8471135029354209\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13852, number of negative: 4997\n",
      "[LightGBM] [Info] Total Bins 11644\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734893 -> initscore=1.019592\n",
      "[LightGBM] [Info] Start training from score 1.019592\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.57317\tvalid_0's f1: 0.847114\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.578372\tvalid_0's f1: 0.847114\n",
      "fold 2 f1 score : 0.8471135029354209\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13852, number of negative: 4998\n",
      "[LightGBM] [Info] Total Bins 11639\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734854 -> initscore=1.019392\n",
      "[LightGBM] [Info] Start training from score 1.019392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.573652\tvalid_0's f1: 0.847217\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.578191\tvalid_0's f1: 0.847217\n",
      "fold 3 f1 score : 0.847217125382263\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13852, number of negative: 4998\n",
      "[LightGBM] [Info] Total Bins 11632\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734854 -> initscore=1.019392\n",
      "[LightGBM] [Info] Start training from score 1.019392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.57331\tvalid_0's f1: 0.847217\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.57816\tvalid_0's f1: 0.847217\n",
      "fold 4 f1 score : 0.847217125382263\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 13852, number of negative: 4998\n",
      "[LightGBM] [Info] Total Bins 11626\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734854 -> initscore=1.019392\n",
      "[LightGBM] [Info] Start training from score 1.019392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.574049\tvalid_0's f1: 0.847217\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.578193\tvalid_0's f1: 0.847217\n",
      "fold 5 f1 score : 0.847217125382263\n",
      "\n",
      "training/predicting question 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12964, number of negative: 5885\n",
      "[LightGBM] [Info] Total Bins 11630\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.687782 -> initscore=0.789770\n",
      "[LightGBM] [Info] Start training from score 0.789770\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.612266\tvalid_0's f1: 0.815085\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.620596\tvalid_0's f1: 0.815085\n",
      "fold 1 f1 score : 0.8150848522941546\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12965, number of negative: 5884\n",
      "[LightGBM] [Info] Total Bins 11632\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.687835 -> initscore=0.790017\n",
      "[LightGBM] [Info] Start training from score 0.790017\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.612255\tvalid_0's f1: 0.814936\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.620718\tvalid_0's f1: 0.814936\n",
      "fold 2 f1 score : 0.8149358813175761\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12965, number of negative: 5885\n",
      "[LightGBM] [Info] Total Bins 11650\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.687798 -> initscore=0.789847\n",
      "[LightGBM] [Info] Start training from score 0.789847\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.612999\tvalid_0's f1: 0.815038\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.620648\tvalid_0's f1: 0.815038\n",
      "fold 3 f1 score : 0.8150383503080599\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12965, number of negative: 5885\n",
      "[LightGBM] [Info] Total Bins 11637\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.687798 -> initscore=0.789847\n",
      "[LightGBM] [Info] Start training from score 0.789847\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.612844\tvalid_0's f1: 0.815038\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.620669\tvalid_0's f1: 0.815038\n",
      "fold 4 f1 score : 0.8150383503080599\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 12965, number of negative: 5885\n",
      "[LightGBM] [Info] Total Bins 11632\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.687798 -> initscore=0.789847\n",
      "[LightGBM] [Info] Start training from score 0.789847\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.613077\tvalid_0's f1: 0.815038\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.620637\tvalid_0's f1: 0.815038\n",
      "fold 5 f1 score : 0.8150383503080599\n",
      "\n",
      "training/predicting question 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['room_fqid'] = df['room_fqid'].str.replace('tunic.', '').str.replace('.', '_')\n",
      "C:\\Users\\Yuchie\\AppData\\Local\\Temp\\ipykernel_3804\\2152105014.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = df.groupby(['session_id'])['fullscreen','hq', 'music'].sum().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## fold 1 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17919, number of negative: 930\n",
      "[LightGBM] [Info] Total Bins 11641\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.950661 -> initscore=2.958432\n",
      "[LightGBM] [Info] Start training from score 2.958432\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.184886\tvalid_0's f1: 0.974655\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.196498\tvalid_0's f1: 0.974655\n",
      "fold 1 f1 score : 0.9746546285217013\n",
      "\n",
      "######################################## fold 2 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17919, number of negative: 930\n",
      "[LightGBM] [Info] Total Bins 11631\n",
      "[LightGBM] [Info] Number of data points in the train set: 18849, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.950661 -> initscore=2.958432\n",
      "[LightGBM] [Info] Start training from score 2.958432\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.184788\tvalid_0's f1: 0.974655\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.196472\tvalid_0's f1: 0.974655\n",
      "fold 2 f1 score : 0.9746546285217013\n",
      "\n",
      "######################################## fold 3 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17919, number of negative: 931\n",
      "[LightGBM] [Info] Total Bins 11631\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.950610 -> initscore=2.957358\n",
      "[LightGBM] [Info] Start training from score 2.957358\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.183865\tvalid_0's f1: 0.974761\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.195887\tvalid_0's f1: 0.974761\n",
      "fold 3 f1 score : 0.9747606614447345\n",
      "\n",
      "######################################## fold 4 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17919, number of negative: 931\n",
      "[LightGBM] [Info] Total Bins 11628\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.950610 -> initscore=2.957358\n",
      "[LightGBM] [Info] Start training from score 2.957358\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.184788\tvalid_0's f1: 0.974761\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.195894\tvalid_0's f1: 0.974761\n",
      "fold 4 f1 score : 0.9747606614447345\n",
      "\n",
      "######################################## fold 5 / fold 5 ########################################\n",
      "[LightGBM] [Info] Number of positive: 17920, number of negative: 930\n",
      "[LightGBM] [Info] Total Bins 11631\n",
      "[LightGBM] [Info] Number of data points in the train set: 18850, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.950663 -> initscore=2.958488\n",
      "[LightGBM] [Info] Start training from score 2.958488\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.188593\tvalid_0's f1: 0.974649\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.196555\tvalid_0's f1: 0.974649\n",
      "fold 5 f1 score : 0.9746491132629747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import log_evaluation\n",
    "\n",
    "# For testing we only use level group 0-4 only, which is question 1 to 3\n",
    "for i in range(1, 19):\n",
    "    print(f\"training/predicting question {i}\")\n",
    "    # Train, validate, and predict models in an OOF way\n",
    "\n",
    "    if i <= 3:\n",
    "        X = train[train['level_group'] == '0-4']\n",
    "        X = feature_engineering(X, '0-4')\n",
    "#         X_test = test_df[test_df['level_group'] == '0-4']\n",
    "    elif i > 3 and i <=13:\n",
    "        X = train[train['level_group'] == '5-12']\n",
    "        X = feature_engineering(X, '5-12')\n",
    "#         X_test = test_df[test_df['level_group'] == '5-12']\n",
    "    else:\n",
    "        X = train[train['level_group'] == '13-22']\n",
    "        X = feature_engineering(X, '13-22')\n",
    "#         X_test = test_df[test_df['level_group'] == '13-22']\n",
    "    \n",
    "    y = labels[labels['question_number'] == i]['correct'].values\n",
    "    X.set_index('session_id', inplace=True)\n",
    "    X.drop('level_group', axis=1, inplace=True)\n",
    "#     X_test.set_index('session_id', inplace=True)\n",
    "#     X_test.drop('level_group', axis=1, inplace=True)\n",
    "\n",
    "    for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "        # Output a phrase that identifies each fold\n",
    "        print('#'*40, f'fold {idx+1} / fold {folds.n_splits}', '#'*40)\n",
    "        \n",
    "        # Train data\n",
    "        X_train, y_train = X.iloc[train_idx], y[train_idx]\n",
    "        # Validation data\n",
    "        X_valid, y_valid = X.iloc[valid_idx], y[valid_idx]\n",
    "\n",
    "        # Convert them to LightGBM dataset\n",
    "        dtrain = lgb.Dataset(X_train, y_train)\n",
    "        dvalid = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "\n",
    "        lgb_model = lgb.train(params=params,\n",
    "                            train_set=dtrain,\n",
    "                            num_boost_round=1000,\n",
    "                            valid_sets=dvalid,\n",
    "                            feval=f1_score_lgb,\n",
    "                            callbacks=[early_stopping(stopping_rounds=100),\n",
    "                                        log_evaluation(100)])\n",
    "        \n",
    "        # OOF prediction using test data\n",
    "#         oof_test_preds[i] += lgb_model.predict(X_test)/folds.n_splits\n",
    "        \n",
    "        # Prediction of validation data target value for model performance evaluation\n",
    "        oof_val_preds[i][valid_idx] += lgb_model.predict(X_valid)\n",
    "        \n",
    "        # Normalized Gini coefficient for prediction probability of validation data\n",
    "        y_pred = np.round(oof_val_preds[i][valid_idx])\n",
    "        score = f1_score(y_valid, y_pred)\n",
    "        lgb_model.save_model(f'basline_{i}.txt')\n",
    "        print(f'fold {idx+1} f1 score : {score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
